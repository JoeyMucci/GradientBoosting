{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "mount_file_id": "11CMNXh2nkUbs2svn5Wv1uUs-uQ_OVAMF",
      "authorship_tag": "ABX9TyNnpKNAzPsRPjjVB/gLGfeT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoeyMucci/GradientBoosting/blob/main/GradientBoostingEMG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uctHU766zo0R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import jax \n",
        "from jax import grad\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import statistics as stat\n",
        "\n",
        "root_directory = 'drive/MyDrive/ColabNotebooks/EMG Data/'\n",
        "\n",
        "filename_to_cat = {\n",
        "    'Slapping.txt' : 1,\n",
        "    'Sidekicking.txt' : 2,\n",
        "    'Pushing.txt' : 3,\n",
        "    'Punching.txt': 4, \n",
        "    'Pulling.txt' : 5,\n",
        "    'Kneeing.txt' : 6,\n",
        "    'Headering.txt' : 7,\n",
        "    'Hamering.txt' : 8, \n",
        "    'Frontkicking.txt' : 9,\n",
        "    'Elbowing.txt' : 10,\n",
        "    'Waving.txt' : 11,\n",
        "    'Walking.txt' : 12,\n",
        "    'Running.txt' : 13,\n",
        "    'Standing.txt' : 14,\n",
        "    'Jumping.txt' : 15,\n",
        "    'Hugging.txt' : 16, \n",
        "    'Handshaking.txt' : 17, \n",
        "    'Seating.txt' : 18, \n",
        "    'Bowing.txt' : 19, \n",
        "    'Clapping.txt' : 20\n",
        "}\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "# Preprocess data, then put into x and y\n",
        "for files in os.walk(root_directory):\n",
        "  for file in files[2]: # for each activity file\n",
        "    x1 = []\n",
        "    x2 = []\n",
        "    x3 = []\n",
        "    f = open(root_directory + file, \"r\")\n",
        "    for line in f: # read data initially\n",
        "      x1.append(line.split())\n",
        "    for i in range(len(x1)): # convert from strings to positive integers\n",
        "      for j in range(8):\n",
        "        x1[i][j] = abs(int(x1[i][j]))\n",
        "    for i in range(len(x1) // 100): # condense data\n",
        "      x2.append(max(x1[i * 100 : i * 100 + 99]))\n",
        "    for i in range(50, len(x2)): # take rolling average of last 50\n",
        "      filler = []\n",
        "      for j in range(8):\n",
        "        filler.append(np.mean(x2[i - 50: i][j]))\n",
        "      x3.append(filler)\n",
        "    for i in range(len(x3)): # add the processed data to x and corresponding label to y\n",
        "      x.append(x3[i])\n",
        "      y.append(filename_to_cat[file])\n",
        "\n",
        "xtrain = []\n",
        "ytrain = []\n",
        "xtest = []\n",
        "ytest = []\n",
        "\n",
        "# Split into test and train sets alternating every row\n",
        "for i in range(len(x)):\n",
        "  if i % 2 == 0:\n",
        "    xtrain.append(x[i])\n",
        "    ytrain.append(y[i])\n",
        "  else:\n",
        "    xtest.append(x[i])\n",
        "    ytest.append(y[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the accuracy of the model\n",
        "def accuracy(yhat, y):\n",
        "  sum = 0\n",
        "  for i in range(len(y)):\n",
        "    if yhat[i] == y[i]:\n",
        "      sum += 1\n",
        "  return sum / len(y)\n",
        "\n",
        "# Our choice of loss function that we will be optimizing \n",
        "def loss_logistic(yhat, y):\n",
        "  return jnp.sum(jnp.log(1 + jnp.exp(-2 * y * yhat)))\n",
        "\n",
        "grad_loss = grad(loss_logistic)  # Jax does the gradient for us!\n",
        "\n",
        "ymodels = []\n",
        "\n",
        "# For every activity, create a binary model\n",
        "for activity in range(1, 21):\n",
        "  # Build training labels\n",
        "  ytrainclass = []\n",
        "  for i in range(len(ytrain)):\n",
        "    if ytrain[i] == activity:\n",
        "      ytrainclass.append(1)\n",
        "    else: ytrainclass.append(-1)\n",
        "\n",
        "  trainmodel = jnp.zeros(len(ytrain))\n",
        "  testmodel = jnp.zeros(len(ytest))\n",
        "\n",
        "  # For every feature, do a series of splits at regular intervals\n",
        "  for f in range(8):\n",
        "    error = grad_loss(trainmodel, jnp.array(ytrainclass)) # We will do regression on this\n",
        "\n",
        "    newtrainmodel = np.zeros(len(ytrain))\n",
        "    newtestmodel = np.zeros(len(ytest))\n",
        "\n",
        "    errorsums = np.zeros(40)\n",
        "    errorcounts = np.zeros(40)\n",
        "\n",
        "    # Calculate the sum and count so average can be calculated later\n",
        "    for i in range(len(ytrain)):\n",
        "      for threshold in range(100, 4100, 100):\n",
        "        if xtrain[i][f] < threshold:\n",
        "          errorsums[(threshold // 100) - 1] += error[i]\n",
        "          errorcounts[(threshold // 100) - 1] += 1\n",
        "          break\n",
        "\n",
        "    # Apply updates (average of error) to both train and test\n",
        "    for i in range(len(ytrain)):\n",
        "      for threshold in range(100, 4100, 100):\n",
        "        if xtrain[i][f] < threshold:\n",
        "          newtrainmodel[i] -= errorsums[(threshold // 100) - 1] / errorcounts[(threshold // 100) - 1]\n",
        "          break\n",
        "\n",
        "    for i in range(len(ytest)):\n",
        "      for threshold in range(100, 4100, 100):\n",
        "        if xtest[i][f] < threshold:\n",
        "          newtestmodel[i] -= errorsums[(threshold // 100) - 1] / errorcounts[(threshold // 100) - 1]\n",
        "          break\n",
        "\n",
        "    # Update both train and test models\n",
        "    trainmodel = trainmodel + newtrainmodel\n",
        "    testmodel = testmodel + newtestmodel\n",
        "  \n",
        "  ymodels.append(testmodel) # Add test model to list of models after all training is done\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# Predict the activity that produces the highest likelihood of matching\n",
        "for i in range(len(xtest)):\n",
        "  maxindex = 0\n",
        "  maxvalue = ymodels[maxindex][i]\n",
        "  for j in range(1, 20):\n",
        "    if(ymodels[j][i] > maxvalue):\n",
        "      maxvalue = ymodels[j][i]\n",
        "      maxindex = j\n",
        "  predictions.append(maxindex + 1)\n",
        "\n",
        "# How likely the model is to predict the correct class from the 20 possible options\n",
        "# No skill model will produce ~0.05\n",
        "print(f\"The accuracy of the model is:{accuracy(ytest, predictions) * 100 : .3f}\")"
      ],
      "metadata": {
        "id": "C6WrHcu8Yc7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0023b04-70d7-4bd2-9aeb-015b4cb63dd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model is: 34.440\n"
          ]
        }
      ]
    }
  ]
}